{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing - School Related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling school-related data first addresses the non-unique properties caused by multiple nearby schools\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the complete dataset\n",
    "rental_df_landing = pd.read_csv('../data/landing/rental_df_landing.csv')\n",
    "\n",
    "rental_df_landing = rental_df_landing.rename(columns={'distance/ç±³': 'distance/m'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHOOL_RELATED = ['id', 'rent', 'address', 'educationLevel', 'name', 'distance/m', 'year', 'gender', 'get_type']\n",
    "\n",
    "# Filter the DataFrame to only include school-related features\n",
    "rental_df_schoolRelated_landing = rental_df_landing[SCHOOL_RELATED]\n",
    "\n",
    "rental_df_schoolRelated_landing.to_csv('../data/landing/rental_df_schoolRelated_landing.csv', index=False)\n",
    "\n",
    "#print(rental_df_schoolRelated_landing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial range of distances: 16.42 to 96330.26 meters\n",
      "Unique values for 'year': ['Prep-6', nan, 'Prep-9', '10-12', '7-12', '3-9', '9-12', 'Prep-12', 'U', 'Unknown', '11-12', '3-12', '7-9', '1-12', '7-11', '5-12', '7', '10-11', '7-10', 'Prep-7', 'U, Prep-6', 'U, Prep-12', 'Prep-8', '11', '3-10', '7-8', '6-10', 'Prep-11', '1-10', 'K-12', 'U, 7-12', '8-12', 'Prep-5', '6-12', 'Prep-3', 'K-6', '3-6', 'U, Prep-9', 'Prep-10', '5']\n",
      "Unique values for 'gender': ['CoEd', nan, 'Girls', 'Boys']\n",
      "Unique values for 'get_type': ['Government', 'Catholic', 'Private']\n"
     ]
    }
   ],
   "source": [
    "# Check the initial range of 'distance/m'\n",
    "distance_range_initial = rental_df_schoolRelated_landing['distance/m'].agg(['min', 'max'])\n",
    "print(f\"Initial range of distances: {distance_range_initial['min']:.2f} to {distance_range_initial['max']:.2f} meters\")\n",
    "\n",
    "# Extract unique values for certain features (year, gender, get_type)\n",
    "features_to_check = ['year', 'gender', 'get_type']\n",
    "unique_feature_values = {}\n",
    "\n",
    "for feature in features_to_check:\n",
    "    unique_feature_values[feature] = rental_df_schoolRelated_landing[feature].unique().tolist()\n",
    "\n",
    "# Print unique values for each feature\n",
    "for feature, values in unique_feature_values.items():\n",
    "    print(f\"Unique values for '{feature}': {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered range of distances: 16.42 to 9998.26 meters\n",
      "Unique values for 'year' after cleaning: ['Prep-6', nan, 'Prep-9', '10-12', '7-12', '3-9', '9-12', 'Prep-12', 'U', 'Unknown', '11-12', '3-12', '7-9', '1-12', '7-11', '5-12', '7', '10-11', '7-10', 'Prep-7', 'Prep-8', '11', '3-10', '7-8', '6-10', 'Prep-11', '1-10', 'K-12', '8-12', 'Prep-5', '6-12', 'Prep-3', 'K-6', '3-6', 'Prep-10', '5']\n"
     ]
    }
   ],
   "source": [
    "min_distance_allowed = 10  # Minimum allowed distance in meters\n",
    "max_distance_allowed = 10000  # Maximum allowed distance in meters\n",
    "\n",
    "# Create a copy of the DataFrame for range checking\n",
    "rental_df_schoolRelated_valid_distance = rental_df_schoolRelated_landing.copy()\n",
    "\n",
    "# Replace distances outside the allowed range with NaN\n",
    "rental_df_schoolRelated_valid_distance.loc[\n",
    "    (rental_df_schoolRelated_valid_distance['distance/m'] < min_distance_allowed) | \n",
    "    (rental_df_schoolRelated_valid_distance['distance/m'] > max_distance_allowed), \n",
    "    'distance/m'] = np.nan\n",
    "\n",
    "# Check the range of distances after range filtering\n",
    "distance_range_filtered = rental_df_schoolRelated_valid_distance['distance/m'].agg(['min', 'max'])\n",
    "print(f\"Filtered range of distances: {distance_range_filtered['min']:.2f} to {distance_range_filtered['max']:.2f} meters\")\n",
    "\n",
    "# Function to select the most common year for properties with multiple years listed\n",
    "def select_most_frequent_year(year_column_value, year_count_dict):\n",
    "    if isinstance(year_column_value, str) and ',' in year_column_value:  # Check for multiple years\n",
    "        years_list = [year.strip() for year in year_column_value.split(',')]\n",
    "        # Find the most common year based on frequency\n",
    "        most_common_year = max(years_list, key=lambda year: year_count_dict[year])\n",
    "        return most_common_year\n",
    "    return year_column_value  # If only one year, return as-is\n",
    "\n",
    "# Create a list of all years for counting frequency\n",
    "all_years_list = [year.strip() for row in rental_df_schoolRelated_valid_distance['year'] if isinstance(row, str) for year in row.split(',')]\n",
    "year_frequency = Counter(all_years_list)\n",
    "\n",
    "# Apply the function to select the most frequent year for each property\n",
    "rental_df_schoolRelated_valid_distance['year'] = \\\n",
    "    rental_df_schoolRelated_valid_distance['year'].apply(lambda year_value: select_most_frequent_year(year_value, year_frequency))\n",
    "\n",
    "print(f\"Unique values for 'year' after cleaning: {rental_df_schoolRelated_valid_distance['year'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicates typically appear because the dataset is scraped using property feature filters, where the same property may be listed under multiple filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6861939</td>\n",
       "      <td>Docklands Primary School</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6861939</td>\n",
       "      <td>Eltham College - Lonsdale Street Campus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6861939</td>\n",
       "      <td>Haileybury College - City Boys</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6861939</td>\n",
       "      <td>Haileybury College - City Girls</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6861939</td>\n",
       "      <td>Hester Hornbrook Academy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                     name  count\n",
       "0  6861939                 Docklands Primary School      2\n",
       "1  6861939  Eltham College - Lonsdale Street Campus      2\n",
       "2  6861939           Haileybury College - City Boys      2\n",
       "3  6861939          Haileybury College - City Girls      2\n",
       "4  6861939                 Hester Hornbrook Academy      2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'id' and 'name' to check for duplicate entries and count occurrences\n",
    "duplicate_check_school = rental_df_schoolRelated_valid_distance.groupby(['id', 'name']).size().reset_index(name='count')\n",
    "\n",
    "duplicate_entries = duplicate_check_school[duplicate_check_school['count'] > 1]\n",
    "\n",
    "# Display the first few rows of the duplicate entries\n",
    "duplicate_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86073, 9)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_df_schoolRelated_no_duplicates = rental_df_schoolRelated_valid_distance.drop_duplicates(subset=['id', 'name'])\n",
    "\n",
    "rental_df_schoolRelated_no_duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the 'rent' value by extracting the numeric amount and removing commas\n",
    "def extract_rent_amount(value):\n",
    "    match = re.search(r'\\$(\\d{1,3}(?:,\\d{3})*|\\d+)(?:\\.\\d+)?', value)  # Find rent in the format $X,XXX or $XXX\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).replace(',', '')  # Remove commas to return a clean number\n",
    "    else:\n",
    "        return np.nan  # Return NaN if no match is found\n",
    "\n",
    "rental_df_schoolRelated_clean_rent = rental_df_schoolRelated_no_duplicates.copy()\n",
    "\n",
    "# Apply the rent cleaning function to the 'rent' column\n",
    "rental_df_schoolRelated_clean_rent['rent'] = rental_df_schoolRelated_clean_rent['rent'].apply(extract_rent_amount)\n",
    "\n",
    "rental_df_schoolRelated_clean_rent['rent'] = pd.to_numeric(rental_df_schoolRelated_clean_rent['rent'], errors='coerce')\n",
    "\n",
    "# Apply a reasonable range for 'rent' values, marking anything outside 10-10000 as NaN\n",
    "rental_df_schoolRelated_clean_rent.loc[\n",
    "    (rental_df_schoolRelated_clean_rent['rent'] < 10) | \n",
    "    (rental_df_schoolRelated_clean_rent['rent'] > 10000), \n",
    "    'rent'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performing the train-test split before handling outliers and missing values ensures that the test set remains untouched by any decisions or patterns learned during the data cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_property_ids = rental_df_schoolRelated_clean_rent['id'].unique()\n",
    "\n",
    "# Split the unique property IDs into train and test sets\n",
    "train_ids, test_ids = train_test_split(unique_property_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training and test datasets by filtering the original dataset based on the train and test IDs\n",
    "train_df_schoolRelated_no_outliers = rental_df_schoolRelated_clean_rent[rental_df_schoolRelated_clean_rent['id'].isin(train_ids)]\n",
    "test_df_schoolRelated_no_outliers = rental_df_schoolRelated_clean_rent[rental_df_schoolRelated_clean_rent['id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate rent by property (id), taking the mean rent per property in the training set\n",
    "rent_agg_train = train_df_schoolRelated_no_outliers.groupby('id').agg({\n",
    "    'rent': 'mean',  \n",
    "}).reset_index()\n",
    "\n",
    "# Calculate the Interquartile Range (IQR) for the aggregated rent values in the training set\n",
    "Q1 = rent_agg_train['rent'].quantile(0.25)\n",
    "Q3 = rent_agg_train['rent'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "n_train = rent_agg_train.shape[0]\n",
    "\n",
    "# Apply the formula: sqrt(log(n)) - 0.5 * IQR if n > 100, otherwise use 1.5 * IQR\n",
    "if n_train > 100:\n",
    "    upper_threshold = Q3 + (np.sqrt(np.log(n_train)) - 0.5) * IQR\n",
    "    lower_threshold = Q1 - (np.sqrt(np.log(n_train)) - 0.5) * IQR\n",
    "else:\n",
    "    upper_threshold = Q3 + 1.5 * IQR\n",
    "    lower_threshold = Q1 - 1.5 * IQR\n",
    "\n",
    "# Replace outliers in the rent values with NaN based on the calculated thresholds in the training set\n",
    "rent_agg_train['rent_cleaned'] = rent_agg_train['rent'].where(\n",
    "    (rent_agg_train['rent'] <= upper_threshold) & (rent_agg_train['rent'] >= lower_threshold), \n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Merge the cleaned rent values back into the original training DataFrame\n",
    "train_df_schoolRelated_no_outliers = train_df_schoolRelated_no_outliers.merge(\n",
    "    rent_agg_train[['id', 'rent_cleaned']], \n",
    "    on='id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Replace original 'rent' values with the cleaned ones in the training set\n",
    "train_df_schoolRelated_no_outliers['rent'] = train_df_schoolRelated_no_outliers['rent_cleaned']\n",
    "\n",
    "# Apply the same thresholds to the test set\n",
    "# Aggregate rent by property (id) in the test set\n",
    "rent_agg_test = test_df_schoolRelated_no_outliers.groupby('id').agg({\n",
    "    'rent': 'mean',  # Option to use median if necessary\n",
    "}).reset_index()\n",
    "\n",
    "# Replace outliers in the rent values with NaN in the test set using the same thresholds as the training set\n",
    "rent_agg_test['rent_cleaned'] = rent_agg_test['rent'].where(\n",
    "    (rent_agg_test['rent'] <= upper_threshold) & (rent_agg_test['rent'] >= lower_threshold), \n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Merge the cleaned rent values back into the original test DataFrame\n",
    "test_df_schoolRelated_no_outliers = test_df_schoolRelated_no_outliers.merge(\n",
    "    rent_agg_test[['id', 'rent_cleaned']], \n",
    "    on='id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Replace original 'rent' values with the cleaned ones in the test set\n",
    "test_df_schoolRelated_no_outliers['rent'] = test_df_schoolRelated_no_outliers['rent_cleaned']\n",
    "\n",
    "train_df_schoolRelated_no_outliers = train_df_schoolRelated_no_outliers.drop(columns=['rent_cleaned'])\n",
    "test_df_schoolRelated_no_outliers = test_df_schoolRelated_no_outliers.drop(columns=['rent_cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial missing values in training set:\n",
      "rent           3710\n",
      "distance/m     1400\n",
      "year          15850\n",
      "gender        16597\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df_schoolRelated_nomiss = train_df_schoolRelated_no_outliers.copy()\n",
    "test_df_schoolRelated_nomiss = test_df_schoolRelated_no_outliers.copy()\n",
    "\n",
    "# Print the number of missing values at the start for key columns in both train and test sets\n",
    "print(\"Initial missing values in training set:\")\n",
    "print(train_df_schoolRelated_nomiss[['rent', 'distance/m', 'year', 'gender']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after filling in training set:\n",
      "rent          0\n",
      "distance/m    0\n",
      "year          0\n",
      "gender        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after filling in test set:\n",
      "rent          0\n",
      "distance/m    0\n",
      "year          0\n",
      "gender        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'rent' with the average rent from the training set\n",
    "average_rent_train = train_df_schoolRelated_nomiss['rent'].mean()\n",
    "train_df_schoolRelated_nomiss['rent'].fillna(average_rent_train, inplace=True)\n",
    "\n",
    "# Fill missing 'distance/m' with the average distance from the training set\n",
    "average_distance_train = train_df_schoolRelated_nomiss['distance/m'].mean()\n",
    "train_df_schoolRelated_nomiss['distance/m'].fillna(average_distance_train, inplace=True)\n",
    "\n",
    "# For 'year', treat 'Unknown' as NaN, then fill NaN with the mode\n",
    "train_df_schoolRelated_nomiss['year'].replace('Unknown', np.nan, inplace=True)\n",
    "year_mode_train = train_df_schoolRelated_nomiss['year'].mode()[0]\n",
    "train_df_schoolRelated_nomiss['year'].fillna(year_mode_train, inplace=True)\n",
    "\n",
    "# Fill missing 'gender' with the mode from the training set\n",
    "gender_mode_train = train_df_schoolRelated_nomiss['gender'].mode()[0]\n",
    "train_df_schoolRelated_nomiss['gender'].fillna(gender_mode_train, inplace=True)\n",
    "\n",
    "# Apply the same logic to the test set (test_df_schoolRelated_no_outliers)\n",
    "test_df_schoolRelated_nomiss['rent'].fillna(average_rent_train, inplace=True)\n",
    "test_df_schoolRelated_nomiss['distance/m'].fillna(average_distance_train, inplace=True)\n",
    "\n",
    "test_df_schoolRelated_nomiss['year'].replace('Unknown', np.nan, inplace=True)\n",
    "test_df_schoolRelated_nomiss['year'].fillna(year_mode_train, inplace=True)\n",
    "\n",
    "test_df_schoolRelated_nomiss['gender'].fillna(gender_mode_train, inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after filling in training set:\")\n",
    "print(train_df_schoolRelated_nomiss[['rent', 'distance/m', 'year', 'gender']].isna().sum())\n",
    "\n",
    "print(\"\\nMissing values after filling in test set:\")\n",
    "print(test_df_schoolRelated_nomiss[['rent', 'distance/m', 'year', 'gender']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved to '../data/raw/train_df_schoolRelated_raw.csv'\n",
      "Test set saved to '../data/raw/test_df_schoolRelated_raw.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned training DataFrame to the specified path\n",
    "train_df_schoolRelated_nomiss.to_csv('../data/raw/train_df_schoolRelated_raw.csv', index=False)\n",
    "\n",
    "# Save the cleaned test DataFrame to the specified path\n",
    "test_df_schoolRelated_nomiss.to_csv('../data/raw/test_df_schoolRelated_raw.csv', index=False)\n",
    "\n",
    "# Print confirmation messages\n",
    "print(\"Training set saved to '../data/raw/train_df_schoolRelated_raw.csv'\")\n",
    "print(\"Test set saved to '../data/raw/test_df_schoolRelated_raw.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curated Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Route Distance Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we prefer to focus on the route distance to schools rather than the straight-line distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get route distances from an API (e.g., Google Maps Distance Matrix API)\n",
    "def get_route_distances(api_key, origin, destinations):\n",
    "    endpoint = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n",
    "    \n",
    "    params = {\n",
    "        'origins': origin, \n",
    "        'destinations': '|'.join(destinations),  \n",
    "        'key': api_key,\n",
    "        'mode': 'driving'  # Change to 'walking' or 'bicycling' if needed\n",
    "    }\n",
    "    \n",
    "    response = requests.get(endpoint, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        return results['rows'][0]['elements']  # Returns distances to each destination\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Step 1: Combine the training and test sets\n",
    "combined_df_schoolRelated = pd.concat([train_df_schoolRelated_nomiss, test_df_schoolRelated_nomiss])\n",
    "\n",
    "# Step 2: Group by 'id' and 'address', aggregating nearby school names\n",
    "combined_rental_df_perProperty = combined_df_schoolRelated.groupby(['id', 'address'])['name'].apply(list).reset_index()\n",
    "\n",
    "to_school_routeDistances = []\n",
    "\n",
    "# Step 3: Calculate route distances for each property\n",
    "for index, property in combined_rental_df_perProperty.iterrows():\n",
    "    property_address = property['address']\n",
    "    school_names = property['name']\n",
    "\n",
    "    # Get distances using the Google API\n",
    "    distances = get_route_distances('___api_key___', property_address, school_names)\n",
    "    \n",
    "    if distances:\n",
    "        for i, school in enumerate(school_names):\n",
    "            distance = {\n",
    "                'id': property['id'],\n",
    "                'address': property_address,\n",
    "                'name': school,\n",
    "                'route_distance/m': distances[i]['distance']['value'] if 'distance' in distances[i] else None\n",
    "            }\n",
    "            to_school_routeDistances.append(distance)\n",
    "\n",
    "# Step 4: Convert the distances list to a DataFrame\n",
    "to_school_routeDistances_df = pd.DataFrame(to_school_routeDistances)\n",
    "\n",
    "# Step 5: Save the route distances DataFrame to a CSV file\n",
    "file_path = '../data/distance/to_school_routeDistances.csv'\n",
    "to_school_routeDistances_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_school_routeDistances_df = pd.read_csv('../data/distance/to_school_routeDistances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_schoolRelated_nomiss['order'] = train_df_schoolRelated_nomiss.index\n",
    "test_df_schoolRelated_nomiss['order'] = test_df_schoolRelated_nomiss.index\n",
    "\n",
    "# Merge school route distances into both train and test sets\n",
    "train_df_schoolRelated_w_routeDistance = pd.merge(train_df_schoolRelated_nomiss, \n",
    "                                                  to_school_routeDistances_df[['id', 'address', 'name', 'route_distance/m']], \n",
    "                                                  on=['id', 'address', 'name'], \n",
    "                                                  how='inner')\n",
    "\n",
    "test_df_schoolRelated_w_routeDistance = pd.merge(test_df_schoolRelated_nomiss, \n",
    "                                                 to_school_routeDistances_df[['id', 'address', 'name', 'route_distance/m']], \n",
    "                                                 on=['id', 'address', 'name'], \n",
    "                                                 how='inner')\n",
    "\n",
    "# Restore the original order in both train and test sets\n",
    "train_df_schoolRelated_w_routeDistance = train_df_schoolRelated_w_routeDistance.sort_values(by='order').reset_index(drop=True)\n",
    "test_df_schoolRelated_w_routeDistance = test_df_schoolRelated_w_routeDistance.sort_values(by='order').reset_index(drop=True)\n",
    "\n",
    "train_df_schoolRelated_nomiss = train_df_schoolRelated_nomiss.drop(columns=['order'])\n",
    "test_df_schoolRelated_nomiss = test_df_schoolRelated_nomiss.drop(columns=['order'])\n",
    "\n",
    "train_df_schoolRelated_w_routeDistance = train_df_schoolRelated_w_routeDistance.drop(columns=['order'])\n",
    "test_df_schoolRelated_w_routeDistance = test_df_schoolRelated_w_routeDistance.drop(columns=['order'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanjunqi/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/shanjunqi/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_route_distances(row, property_avg_ratios, dataset_avg_ratio):\n",
    "    if pd.isna(row['route_distance/m']): \n",
    "        property_avg_ratio = property_avg_ratios.get(row['id'], np.nan)\n",
    "        if not pd.isna(property_avg_ratio): \n",
    "            return row['distance/m'] * property_avg_ratio\n",
    "        else:  \n",
    "            return row['distance/m'] * dataset_avg_ratio\n",
    "    return row['route_distance/m']\n",
    "\n",
    "# Feature engineering on training data\n",
    "def clean_school_route_distances_train(df):\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # Create distance_ratio\n",
    "    df_cleaned['distance_ratio'] = df.apply(\n",
    "        lambda row: row['route_distance/m'] / row['distance/m'] if not pd.isna(row['route_distance/m']) else np.nan, axis=1\n",
    "    )\n",
    "    \n",
    "    # Apply thresholds for distance_ratio\n",
    "    upper_ratio_threshold = 5\n",
    "    lower_ratio_threshold = 0.2\n",
    "\n",
    "    df_cleaned.loc[\n",
    "        (df_cleaned['distance_ratio'] > upper_ratio_threshold) |\n",
    "        (df_cleaned['distance_ratio'] < lower_ratio_threshold), \n",
    "        ['route_distance/m', 'distance_ratio']] = np.nan\n",
    "\n",
    "    # Calculate property and dataset averages based on training data\n",
    "    property_avg_ratios = df_cleaned.groupby('id')['distance_ratio'].apply(\n",
    "        lambda x: np.mean([val for val in x if not pd.isna(val)])\n",
    "    )\n",
    "    \n",
    "    dataset_avg_ratio = df_cleaned['distance_ratio'].apply(\n",
    "        lambda x: x if not pd.isna(x) else np.nan\n",
    "    ).mean()\n",
    "    \n",
    "    # Fill missing route distances\n",
    "    df_cleaned['route_distance/m'] = df_cleaned.apply(\n",
    "        fill_missing_route_distances, axis=1, property_avg_ratios=property_avg_ratios, dataset_avg_ratio=dataset_avg_ratio\n",
    "    )\n",
    "    \n",
    "    # Drop the 'distance_ratio' column\n",
    "    df_cleaned = df_cleaned.drop(columns=['distance_ratio'])\n",
    "    \n",
    "    return df_cleaned, property_avg_ratios, dataset_avg_ratio\n",
    "\n",
    "# Feature engineering on test data using stats from training data\n",
    "def clean_school_route_distances_test(df, property_avg_ratios, dataset_avg_ratio):\n",
    "    df_cleaned = df.copy()\n",
    "\n",
    "    # Create distance_ratio\n",
    "    df_cleaned['distance_ratio'] = df.apply(\n",
    "        lambda row: row['route_distance/m'] / row['distance/m'] if not pd.isna(row['route_distance/m']) else np.nan, axis=1\n",
    "    )\n",
    "\n",
    "    # Apply thresholds for distance_ratio\n",
    "    upper_ratio_threshold = 5\n",
    "    lower_ratio_threshold = 0.2\n",
    "\n",
    "    df_cleaned.loc[\n",
    "        (df_cleaned['distance_ratio'] > upper_ratio_threshold) |\n",
    "        (df_cleaned['distance_ratio'] < lower_ratio_threshold), \n",
    "        ['route_distance/m', 'distance_ratio']] = np.nan\n",
    "\n",
    "    # Fill missing route distances using training stats\n",
    "    df_cleaned['route_distance/m'] = df_cleaned.apply(\n",
    "        fill_missing_route_distances, axis=1, property_avg_ratios=property_avg_ratios, dataset_avg_ratio=dataset_avg_ratio\n",
    "    )\n",
    "\n",
    "    # Drop the 'distance_ratio' column\n",
    "    df_cleaned = df_cleaned.drop(columns=['distance_ratio'])\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Clean train dataset and compute ratios\n",
    "train_df_schoolRelated_w_cleaned_routeDistance, property_avg_ratios_train, dataset_avg_ratio_train = clean_school_route_distances_train(train_df_schoolRelated_w_routeDistance)\n",
    "\n",
    "# Clean test dataset using the ratios from the train dataset\n",
    "test_df_schoolRelated_w_cleaned_routeDistance = clean_school_route_distances_test(test_df_schoolRelated_w_routeDistance, property_avg_ratios_train, dataset_avg_ratio_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process fills missing route distances by calculating property-specific and dataset-wide ratios in the training data and applying these ratios to fill missing values in both the training and test sets, ensuring consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- School Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the school score by using a Random Forest model to estimate the rental prices of its nearby properties based on school attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical features related to schools\n",
    "school_related_categorical = ['educationLevel', 'year', 'gender', 'get_type']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "school_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the training dataset\n",
    "school_encoded_train = school_encoder.fit_transform(train_df_schoolRelated_w_cleaned_routeDistance[school_related_categorical])\n",
    "\n",
    "# Transform the test dataset using the same encoder (no refit)\n",
    "school_encoded_test = school_encoder.transform(test_df_schoolRelated_w_cleaned_routeDistance[school_related_categorical])\n",
    "\n",
    "# Get encoded feature names\n",
    "encoded_feature_names = school_encoder.get_feature_names_out(school_related_categorical)\n",
    "\n",
    "# Create DataFrames for encoded train and test sets\n",
    "train_df_schoolRelated_encoded = pd.DataFrame(school_encoded_train, columns=encoded_feature_names)\n",
    "train_df_schoolRelated_encoded['id'] = train_df_schoolRelated_w_cleaned_routeDistance['id']\n",
    "train_df_schoolRelated_encoded['rent'] = train_df_schoolRelated_w_cleaned_routeDistance['rent']\n",
    "train_df_schoolRelated_encoded['route_distance/m'] = train_df_schoolRelated_w_cleaned_routeDistance['route_distance/m']\n",
    "\n",
    "test_df_schoolRelated_encoded = pd.DataFrame(school_encoded_test, columns=encoded_feature_names)\n",
    "test_df_schoolRelated_encoded['id'] = test_df_schoolRelated_w_cleaned_routeDistance['id']\n",
    "test_df_schoolRelated_encoded['rent'] = test_df_schoolRelated_w_cleaned_routeDistance['rent']\n",
    "test_df_schoolRelated_encoded['route_distance/m'] = test_df_schoolRelated_w_cleaned_routeDistance['route_distance/m']\n",
    "\n",
    "# Organize columns\n",
    "train_df_schoolRelated_encoded = train_df_schoolRelated_encoded[['id', 'rent'] + list(encoded_feature_names) + ['route_distance/m']]\n",
    "test_df_schoolRelated_encoded = test_df_schoolRelated_encoded[['id', 'rent'] + list(encoded_feature_names) + ['route_distance/m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation on training set\n",
    "school_related_features = list(encoded_feature_names)\n",
    "\n",
    "# X and y for the training set\n",
    "X_train = train_df_schoolRelated_encoded[school_related_features]\n",
    "y_train = train_df_schoolRelated_encoded['rent']\n",
    "\n",
    "# Define cross-validation and model\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validated predictions on the training set (for score calculation)\n",
    "predicted_rent_train = cross_val_predict(rf_model, X_train, y_train, cv=cv)\n",
    "\n",
    "# Fit the model on the full training set and predict the test set\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# X for the test set\n",
    "X_test = test_df_schoolRelated_encoded[school_related_features]\n",
    "\n",
    "# Predict rent for the test set\n",
    "predicted_rent_test = rf_model.predict(X_test)\n",
    "\n",
    "# Assign the cross-validated predictions back to the training set as 'school_score'\n",
    "train_df_schoolRelated_encoded['school_score'] = predicted_rent_train\n",
    "\n",
    "# Assign the predictions for the test set as 'school_score'\n",
    "test_df_schoolRelated_encoded['school_score'] = predicted_rent_test\n",
    "\n",
    "# Save the updated DataFrames with the school score\n",
    "train_df_schoolRelated_w_schoolScore = train_df_schoolRelated_encoded.copy()\n",
    "test_df_schoolRelated_w_schoolScore = test_df_schoolRelated_encoded.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculating Education Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a MinMaxScaler for normalizing the school scores\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize school scores for the training set\n",
    "school_score_reshaped_train = train_df_schoolRelated_w_schoolScore['school_score'].values.reshape(-1, 1)\n",
    "school_score_normalized_train = scaler.fit_transform(school_score_reshaped_train)\n",
    "train_df_schoolRelated_w_schoolScore['school_score'] = school_score_normalized_train\n",
    "\n",
    "# Normalize school scores for the test set using the scaler fitted on the training data\n",
    "school_score_reshaped_test = test_df_schoolRelated_w_schoolScore['school_score'].values.reshape(-1, 1)\n",
    "school_score_normalized_test = scaler.transform(school_score_reshaped_test)\n",
    "test_df_schoolRelated_w_schoolScore['school_score'] = school_score_normalized_test\n",
    "\n",
    "# Normalize reverse distance for both train and test sets using MinMaxScaler\n",
    "distance_scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize reverse distance for the training set\n",
    "train_df_schoolRelated_w_schoolScore['reverse_distance/m'] = 1 - distance_scaler.fit_transform(\n",
    "    train_df_schoolRelated_w_schoolScore[['route_distance/m']]\n",
    ")\n",
    "\n",
    "# Normalize reverse distance for the test set using the scaler fitted on training data\n",
    "test_df_schoolRelated_w_schoolScore['reverse_distance/m'] = 1 - distance_scaler.transform(\n",
    "    test_df_schoolRelated_w_schoolScore[['route_distance/m']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate education index equally important score for both train and test sets\n",
    "train_df_schoolRelated_w_schoolScore['education_index_equally_important_score'] = (\n",
    "    0.5 * train_df_schoolRelated_w_schoolScore['school_score'] + 0.5 * train_df_schoolRelated_w_schoolScore['reverse_distance/m']\n",
    ")\n",
    "\n",
    "test_df_schoolRelated_w_schoolScore['education_index_equally_important_score'] = (\n",
    "    0.5 * test_df_schoolRelated_w_schoolScore['school_score'] + 0.5 * test_df_schoolRelated_w_schoolScore['reverse_distance/m']\n",
    ")\n",
    "\n",
    "# Normalize the education index equally important score for both train and test sets\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize for the training set\n",
    "train_df_schoolRelated_w_schoolScore['education_index_equally_important_score'] = scaler.fit_transform(\n",
    "    train_df_schoolRelated_w_schoolScore[['education_index_equally_important_score']]\n",
    ")\n",
    "\n",
    "# Normalize for the test set using the scaler fitted on the training set\n",
    "test_df_schoolRelated_w_schoolScore['education_index_equally_important_score'] = scaler.transform(\n",
    "    test_df_schoolRelated_w_schoolScore[['education_index_equally_important_score']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the education index by summing the scores of the top 5 nearest schools\n",
    "def compute_education_index(group):\n",
    "    nearest_schools = group.sort_values(by='education_index_equally_important_score', ascending=False).head(5)\n",
    "    education_index = np.sum(nearest_schools['education_index_equally_important_score'])\n",
    "    return education_index\n",
    "\n",
    "# Apply this function to compute the education index for each property in train and test sets\n",
    "train_education_index = train_df_schoolRelated_w_schoolScore.groupby('id').apply(lambda group: compute_education_index(group))\n",
    "test_education_index = test_df_schoolRelated_w_schoolScore.groupby('id').apply(lambda group: compute_education_index(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the education index into the train and test rental datasets\n",
    "train_df_schoolRelated_w_educationIndex = train_df_schoolRelated_nomiss.copy()\n",
    "test_df_schoolRelated_w_educationIndex = test_df_schoolRelated_nomiss.copy()\n",
    "\n",
    "school_related_columns_to_drop = ['educationLevel', 'name', 'distance/m', 'year', 'gender', 'get_type']\n",
    "\n",
    "train_df_schoolRelated_w_educationIndex = train_df_schoolRelated_w_educationIndex.drop(columns=school_related_columns_to_drop)\n",
    "train_df_schoolRelated_w_educationIndex = train_df_schoolRelated_w_educationIndex.drop_duplicates(subset='id', keep='first')\n",
    "\n",
    "test_df_schoolRelated_w_educationIndex = test_df_schoolRelated_w_educationIndex.drop(columns=school_related_columns_to_drop)\n",
    "test_df_schoolRelated_w_educationIndex = test_df_schoolRelated_w_educationIndex.drop_duplicates(subset='id', keep='first')\n",
    "\n",
    "# Merge the education index back into the train and test rental datasets\n",
    "train_df_schoolRelated_w_educationIndex = pd.merge(\n",
    "    train_df_schoolRelated_w_educationIndex, \n",
    "    train_education_index.rename('educationIndex'), \n",
    "    left_on='id', right_index=True, how='inner'\n",
    ")\n",
    "\n",
    "test_df_schoolRelated_w_educationIndex = pd.merge(\n",
    "    test_df_schoolRelated_w_educationIndex, \n",
    "    test_education_index.rename('educationIndex'), \n",
    "    left_on='id', right_index=True, how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved to '../data/curated/train_df_schoolRelated_curated.csv'\n",
      "Test set saved to '../data/curated/test_df_schoolRelated_curated.csv'\n"
     ]
    }
   ],
   "source": [
    "train_df_schoolRelated_w_educationIndex.to_csv('../data/curated/train_df_schoolRelated_curated.csv', index=False)\n",
    "\n",
    "test_df_schoolRelated_w_educationIndex.to_csv('../data/curated/test_df_schoolRelated_curated.csv', index=False)\n",
    "\n",
    "print(\"Training set saved to '../data/curated/train_df_schoolRelated_curated.csv'\")\n",
    "print(\"Test set saved to '../data/curated/test_df_schoolRelated_curated.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
